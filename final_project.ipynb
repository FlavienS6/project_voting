{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7054bcfb-47c6-46ee-9a44-f1d31165bb68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  year     state state_po county_name  county_fips        office  \\\n",
      "0       11161  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "1       11162  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "2       11163  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "3       11164  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "4       11165  2000  VIRGINIA       VA   ALBEMARLE        51003  US PRESIDENT   \n",
      "\n",
      "        candidate       party  candidatevotes  totalvotes   version   mode  \n",
      "0         AL GORE    DEMOCRAT            5092       11925  20220315  TOTAL  \n",
      "1  GEORGE W. BUSH  REPUBLICAN            6352       11925  20220315  TOTAL  \n",
      "2     RALPH NADER       GREEN             220       11925  20220315  TOTAL  \n",
      "3           OTHER       OTHER             261       11925  20220315  TOTAL  \n",
      "4         AL GORE    DEMOCRAT           16255       36846  20220315  TOTAL  \n",
      "Unnamed: 0        0\n",
      "year              0\n",
      "state             0\n",
      "state_po          0\n",
      "county_name       0\n",
      "county_fips       0\n",
      "office            0\n",
      "candidate         0\n",
      "party             0\n",
      "candidatevotes    0\n",
      "totalvotes        0\n",
      "version           0\n",
      "mode              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/voting_VA.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a20499d6-3341-4658-a7b7-ff49bc3dfc47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VIRGINIA']\n",
      "['VA']\n",
      "['US PRESIDENT']\n",
      "['TOTAL' 'ABSENTEE' 'ELECTION DAY' 'PROVISIONAL']\n"
     ]
    }
   ],
   "source": [
    "# Remove the 'Unnamed: 0' column\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Check unique values for certain columns to ensure consistency\n",
    "print(df['state'].unique())  # Should only contain \"VIRGINIA\"\n",
    "print(df['state_po'].unique())  # Should only contain \"VA\"\n",
    "print(df['office'].unique())  # Should only contain \"US PRESIDENT\"\n",
    "print(df['mode'].unique())  # Check if any action is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "874afb6e-c5ee-43a6-b1ee-6e93e0283868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TOTAL\n",
       "1    TOTAL\n",
       "2    TOTAL\n",
       "3    TOTAL\n",
       "4    TOTAL\n",
       "Name: mode, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e1d67170-3ebd-4533-aac7-da775ef97aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TOTAL\n",
       "1    TOTAL\n",
       "2    TOTAL\n",
       "3    TOTAL\n",
       "4    TOTAL\n",
       "Name: mode, dtype: category\n",
       "Categories (4, object): ['ABSENTEE', 'ELECTION DAY', 'PROVISIONAL', 'TOTAL']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we're interested in overall voting results without differentiating between the modes:\n",
    "# df_total = df[df['mode'] == 'TOTAL']\n",
    "# df_total.to_csv(\"data/clean_total_voting_VA.csv\", index=False) \n",
    "\n",
    "# Otherwise, we can keep all of the modes of voting and use them as features\n",
    "# in our models\n",
    "df['mode'] = df['mode'].astype('category')\n",
    "df['mode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "99ff999a-78c2-45d6-91ed-41206bb48c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>candidatevotes</th>\n",
       "      <th>totalvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5092</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>GEORGE W. BUSH</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>6352</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>261</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>RALPH NADER</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>220</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALBEMARLE</td>\n",
       "      <td>51003</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>16255</td>\n",
       "      <td>36846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year county_name  county_fips       candidate       party  candidatevotes  \\\n",
       "0  2000    ACCOMACK        51001         AL GORE    DEMOCRAT            5092   \n",
       "1  2000    ACCOMACK        51001  GEORGE W. BUSH  REPUBLICAN            6352   \n",
       "2  2000    ACCOMACK        51001           OTHER       OTHER             261   \n",
       "3  2000    ACCOMACK        51001     RALPH NADER       GREEN             220   \n",
       "4  2000   ALBEMARLE        51003         AL GORE    DEMOCRAT           16255   \n",
       "\n",
       "   totalvotes  \n",
       "0       11925  \n",
       "1       11925  \n",
       "2       11925  \n",
       "3       11925  \n",
       "4       36846  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provides a dataframe where the modes aggregates all individual records across different voting modes \n",
    "# into a single record per candidate per county per election year. \n",
    "\n",
    "df_aggregated = df.groupby(['year', 'county_name', 'county_fips', 'candidate', 'party']).agg({\n",
    "    'candidatevotes': 'sum',\n",
    "    'totalvotes': 'max'  # Assuming totalvotes is the same across all modes, otherwise sum might be needed\n",
    "}).reset_index()\n",
    "\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61f88c43-1624-4b01-8857-642db8472e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>net_total</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>1260</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALBEMARLE</td>\n",
       "      <td>51003</td>\n",
       "      <td>2036</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALEXANDRIA</td>\n",
       "      <td>51510</td>\n",
       "      <td>-14590</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALLEGHANY</td>\n",
       "      <td>51005</td>\n",
       "      <td>594</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>AMELIA</td>\n",
       "      <td>51007</td>\n",
       "      <td>1193</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year county_name  county_fips  net_total      winner\n",
       "0  2000    ACCOMACK        51001       1260  REPUBLICAN\n",
       "1  2000   ALBEMARLE        51003       2036  REPUBLICAN\n",
       "2  2000  ALEXANDRIA        51510     -14590    DEMOCRAT\n",
       "3  2000   ALLEGHANY        51005        594  REPUBLICAN\n",
       "4  2000      AMELIA        51007       1193  REPUBLICAN"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#removing candidates column (unimportant)\n",
    "df_real = df_aggregated.drop('candidate', axis=1)\n",
    "#removing third parties (also unimportant)\n",
    "df_real = df_real[~df_real['party'].isin(['OTHER', 'GREEN'])]\n",
    "#finding net total votes\n",
    "df_real['net_total'] = df_real.groupby(['year', 'county_name', 'county_fips', 'totalvotes'])['candidatevotes'].transform(lambda x: x.iloc[1] - x.iloc[0])\n",
    "\n",
    "# merging columns\n",
    "df_real = df_real.groupby(['year', 'county_name', 'county_fips', 'totalvotes', 'net_total']).agg({'party': ', '.join}).reset_index()\n",
    "df_real['winner'] = df_real['net_total'].apply(lambda x: 'REPUBLICAN' if x > 0 else 'DEMOCRAT')\n",
    "#dropping some more columns\n",
    "df_real = df_real.drop(['party', 'totalvotes'], axis=1)\n",
    "df_final = df_real[['year', 'county_name', 'county_fips','net_total', 'winner']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cfa372fe-8fd6-4372-8df3-755e316175c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year county_name county_fips  net_total      winner     AV0AA     B78AA  \\\n",
      "0  2000    ACCOMACK       51001       1260  REPUBLICAN   38305.0   38305.0   \n",
      "1  2004    ACCOMACK       51001      -2208    DEMOCRAT   38305.0   38305.0   \n",
      "2  2000   ALBEMARLE       51003       2036  REPUBLICAN   79236.0   79236.0   \n",
      "3  2004   ALBEMARLE       51003        899  REPUBLICAN   79236.0   79236.0   \n",
      "4  2000  ALEXANDRIA       51510     -14590    DEMOCRAT  128283.0  128283.0   \n",
      "\n",
      "     AV1AA    AV1AB    AT5AA    AT5AB    AL8AA    AL8AB    AL8AC    AL8AD  \\\n",
      "0  18590.0  19715.0  36680.0   1625.0  22535.0  13983.0   4495.0    963.0   \n",
      "1  18590.0  19715.0  36680.0   1625.0  22535.0  13983.0   4495.0    963.0   \n",
      "2  38002.0  41234.0  73483.0   5753.0  39195.0  33535.0  12676.0   6028.0   \n",
      "3  38002.0  41234.0  73483.0   5753.0  39195.0  33535.0  12676.0   6028.0   \n",
      "4  61974.0  66309.0  95683.0  32600.0  27840.0  65288.0  21004.0  11976.0   \n",
      "\n",
      "     AL8AE   AL8AF   AL8AG  AL8AH    AL9AA    AL9AB    AL9AC    AL9AD  \\\n",
      "0   8010.0   515.0   162.0    NaN  22535.0  13983.0   4495.0    963.0   \n",
      "1   8010.0   515.0   162.0    NaN  22535.0  13983.0   4495.0    963.0   \n",
      "2  11796.0  3035.0   753.0    NaN  39195.0  33535.0  12676.0   6028.0   \n",
      "3  11796.0  3035.0   753.0    NaN  39195.0  33535.0  12676.0   6028.0   \n",
      "4  26329.0  5979.0  2555.0    NaN  27840.0  65288.0  21004.0  11976.0   \n",
      "\n",
      "     AL9AE   AL9AF   AL9AG  AL9AH  AL9AI   AL9AJ   AK7AA   AK7AB   AK7AC  \\\n",
      "0   8010.0   515.0   162.0    7.0    5.0   150.0   117.0   112.0     8.0   \n",
      "1   8010.0   515.0   162.0    7.0    5.0   150.0   117.0   112.0     8.0   \n",
      "2  11796.0  3035.0   753.0   44.0   28.0   681.0  1732.0  2127.0   240.0   \n",
      "3  11796.0  3035.0   753.0   44.0   28.0   681.0  1732.0  2127.0   240.0   \n",
      "4  26329.0  5979.0  2555.0  484.0   97.0  1974.0  2790.0  8059.0  7665.0   \n",
      "\n",
      "   AK7AD    AK7AE  AK7AF  AB9AA  AB9AB  AB9AC  AB9AD  AB9AE  AB9AF  AB9AG  \\\n",
      "0    0.0   1388.0    0.0    0.0    0.0   32.0    3.0   10.0   27.0   11.0   \n",
      "1    0.0   1388.0    0.0    0.0    0.0   32.0    3.0   10.0   27.0   11.0   \n",
      "2  107.0   1547.0    0.0   25.0   19.0  489.0   25.0  111.0  330.0   77.0   \n",
      "3  107.0   1547.0    0.0   25.0   19.0  489.0   25.0  111.0  330.0   77.0   \n",
      "4   62.0  14024.0    0.0   68.0   38.0  558.0   18.0  239.0  517.0    9.0   \n",
      "\n",
      "   AB9AH  AB9AI  AB9AJ  AB9AK  AB9AL  AB9AM  AB9AN  AB9AO  AB9AP  AB9AQ  \\\n",
      "0    0.0    2.0    2.0    0.0   12.0    4.0   14.0    0.0   19.0    4.0   \n",
      "1    0.0    2.0    2.0    0.0   12.0    4.0   14.0    0.0   19.0    4.0   \n",
      "2   50.0   88.0   18.0   43.0    8.0   79.0  216.0  154.0  779.0  155.0   \n",
      "3   50.0   88.0   18.0   43.0    8.0   79.0  216.0  154.0  779.0  155.0   \n",
      "4   96.0  114.0   17.0   24.0   87.0   97.0  568.0  340.0  561.0  203.0   \n",
      "\n",
      "    AB9AR   AB9AS  AB9AT  AB9AU   AB9AV  AB9AW    AB9AX  AB9AY  AJ6AA  AJ6AB  \\\n",
      "0    89.0     8.0    0.0    0.0   794.0   26.0    568.0    0.0    NaN    NaN   \n",
      "1    89.0     8.0    0.0    0.0   794.0   26.0    568.0    0.0    NaN    NaN   \n",
      "2  1193.0   240.0  107.0    3.0   648.0  335.0    561.0    0.0    NaN    NaN   \n",
      "3  1193.0   240.0  107.0    3.0   648.0  335.0    561.0    0.0    NaN    NaN   \n",
      "4  7295.0  7665.0   62.0  143.0  1119.0  467.0  12295.0    0.0    NaN    NaN   \n",
      "\n",
      "   AJ6AC  AJ6AD  AJ6AE  AJ6AF  AJ6AG  AJ6AH  AJ6AI  AJ6AJ  AJ6AK  AJ6AL  \\\n",
      "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "1    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   AJ6AM  AJ6AN  AJ6AO  AJ6AP  AJ6AQ  AJ6AR  AJ6AS  AJ6AT  AJ6AU  AJ6AV  \\\n",
      "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "1    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   AJ6AW  AJ6AX  AJ6AY  AJ6AZ  AJ6BA  AJ6BB  AJ6BC  AJ6BD   B69AA    B69AB  \\\n",
      "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  3078.0  19308.0   \n",
      "1    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  3078.0  19308.0   \n",
      "2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  2844.0  25328.0   \n",
      "3    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  2844.0  25328.0   \n",
      "4    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  6282.0  37466.0   \n",
      "\n",
      "     B69AC    B84AA   B84AB    B84AC    B84AD   B84AE    B84AF   A63AA  \\\n",
      "0   3508.0  18116.0   133.0  17983.0  16618.0  1365.0  11932.0   992.0   \n",
      "1   3508.0  18116.0   133.0  17983.0  16618.0  1365.0  11932.0   992.0   \n",
      "2  25675.0  41043.0   184.0  40859.0  39584.0  1275.0  20572.0  1517.0   \n",
      "3  25675.0  41043.0   184.0  40859.0  39584.0  1275.0  20572.0  1517.0   \n",
      "4  51982.0  80949.0  1861.0  79088.0  76584.0  2504.0  27815.0  1625.0   \n",
      "\n",
      "    A63AB    A63AC    A63AD    A63AE   A63AF    BS4AA   BS4AB    BS4AC  \\\n",
      "0  1744.0   3547.0   4795.0   6097.0   941.0   9542.0   130.0   9412.0   \n",
      "1  1744.0   3547.0   4795.0   6097.0   941.0   9542.0   130.0   9412.0   \n",
      "2  3244.0   8830.0  11263.0  14778.0  1411.0  21136.0   161.0  20975.0   \n",
      "3  3244.0   8830.0  11263.0  14778.0  1411.0  21136.0   161.0  20975.0   \n",
      "4  7392.0  27998.0  19958.0  22133.0  1843.0  41538.0  1409.0  40129.0   \n",
      "\n",
      "     BS4AD   BS4AE    BS4AF    BS4AG  BS4AH    BS4AI    BS4AJ   BS4AK  \\\n",
      "0   8743.0   669.0   4610.0   8574.0    3.0   8571.0   7875.0   696.0   \n",
      "1   8743.0   669.0   4610.0   8574.0    3.0   8571.0   7875.0   696.0   \n",
      "2  20357.0   618.0   8039.0  19907.0   23.0  19884.0  19227.0   657.0   \n",
      "3  20357.0   618.0   8039.0  19907.0   23.0  19884.0  19227.0   657.0   \n",
      "4  38929.0  1200.0  10566.0  39411.0  452.0  38959.0  37655.0  1304.0   \n",
      "\n",
      "     BS4AL  A67AA   A67AB    A67AC    A67AD    A67AE  A67AF  A67AG   A67AH  \\\n",
      "0   7322.0  479.0   871.0   1883.0   2545.0   3201.0  563.0  513.0   873.0   \n",
      "1   7322.0  479.0   871.0   1883.0   2545.0   3201.0  563.0  513.0   873.0   \n",
      "2  12533.0  736.0  1629.0   4505.0   5693.0   7711.0  862.0  781.0  1615.0   \n",
      "3  12533.0  736.0  1629.0   4505.0   5693.0   7711.0  862.0  781.0  1615.0   \n",
      "4  17249.0  726.0  3748.0  14338.0  10610.0  11123.0  993.0  899.0  3644.0   \n",
      "\n",
      "     A67AI   A67AJ    A67AK  A67AL    C54AA    C54AB   C54AC   C54AD  C54AE  \\\n",
      "0   1664.0  2250.0   2896.0  378.0  14839.0    256.0   256.0     0.0    0.0   \n",
      "1   1664.0  2250.0   2896.0  378.0  14839.0    256.0   256.0     0.0    0.0   \n",
      "2   4325.0  5570.0   7067.0  549.0  35542.0    640.0   616.0    18.0    6.0   \n",
      "3   4325.0  5570.0   7067.0  549.0  35542.0    640.0   616.0    18.0    6.0   \n",
      "4  13660.0  9348.0  11010.0  850.0  58645.0  12279.0  4994.0  7192.0   93.0   \n",
      "\n",
      "   C54AF   C54AG  C54AH   C54AI  C50AA   C50AB   C50AC   C50AD    C50AE  \\\n",
      "0    0.0   422.0  333.0   454.0  919.0  2429.0  2813.0  2681.0   3206.0   \n",
      "1    0.0   422.0  333.0   454.0  919.0  2429.0  2813.0  2681.0   3206.0   \n",
      "2   24.0   594.0  326.0  2011.0  764.0  3099.0  6453.0  8199.0   9931.0   \n",
      "3   24.0   594.0  326.0  2011.0  764.0  3099.0  6453.0  8199.0   9931.0   \n",
      "4  358.0  2289.0  927.0  2692.0  959.0  3541.0  7414.0  9888.0  15737.0   \n",
      "\n",
      "     C50AF    C50AG   C50AH      C98AA   BS7AA   BS7AB   BS7AC    BS7AD  \\\n",
      "0   1979.0    725.0  1098.0   364875.0  2186.0  1339.0  2799.0   8946.0   \n",
      "1   1979.0    725.0  1098.0   364875.0  2186.0  1339.0  2799.0   8946.0   \n",
      "2   6076.0   1097.0  1507.0   828400.0  1976.0  1383.0  3162.0  25395.0   \n",
      "3   6076.0   1097.0  1507.0   828400.0  1976.0  1383.0  3162.0  25395.0   \n",
      "4  20663.0  10375.0  5921.0  2210800.0  3408.0  1949.0  4754.0  51857.0   \n",
      "\n",
      "     B79AA   A88AA  A88AB   A88AC   A88AD    A88AE    AB2AA    BD5AA  \\\n",
      "0  30250.0   846.0  757.0  1803.0  3781.0   3195.0  34821.0  16309.0   \n",
      "1  30250.0   846.0  757.0  1803.0  3781.0   3195.0  34821.0  16309.0   \n",
      "2  50749.0   577.0  506.0  1523.0  5153.0  13401.0  63407.0  28852.0   \n",
      "3  50749.0   577.0  506.0  1523.0  5153.0  13401.0  63407.0  28852.0   \n",
      "4  56054.0  1213.0  866.0  2114.0  6275.0  17685.0  67023.0  37645.0   \n",
      "\n",
      "      AX6AA    CL6AA    AX7AA     AX7AB  BV8AA   BV8AB  \n",
      "0   37715.0   6788.0   6788.0   30927.0  957.0  5291.0  \n",
      "1   37715.0   6788.0   6788.0   30927.0  957.0  5291.0  \n",
      "2   77661.0   5232.0   5232.0   72429.0  430.0  8756.0  \n",
      "3   77661.0   5232.0   5232.0   72429.0  430.0  8756.0  \n",
      "4  126409.0  11279.0  11279.0  115130.0  939.0  9547.0  \n"
     ]
    }
   ],
   "source": [
    "df_melt = pd.read_csv(\"data/df_melt.csv\")\n",
    "\n",
    "year_mapping = {\n",
    "    2000: 2000,\n",
    "    2004: 2000,\n",
    "    2008: 125,\n",
    "    2012: 125,\n",
    "    2016: 195,\n",
    "    2020: 195\n",
    "}\n",
    "df_final['melt_year'] = df_final['year'].map(year_mapping)\n",
    "\n",
    "# Convert columns to the same data type before merging\n",
    "df_final['melt_year'] = df_final['melt_year'].astype(str)\n",
    "df_final['county_fips'] = df_final['county_fips'].astype(str)\n",
    "df_melt['YEAR'] = df_melt['YEAR'].astype(str)\n",
    "df_melt['FIPS'] = df_melt['FIPS'].astype(str)\n",
    "\n",
    "merged_df = pd.merge(df_final, df_melt, left_on=['melt_year', 'county_fips'], right_on=['YEAR', 'FIPS'])\n",
    "\n",
    "columns_to_drop = ['YEAR', 'FIPS', 'melt_year']\n",
    "df_updated = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(df_updated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "49e6f5dc-867d-4184-b39c-f87d95aa5511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_updated = df_updated.drop(columns=['county_name','winner'])\n",
    "df_updated = df_updated.astype(float)\n",
    "df_2020 = df_updated[df_updated['year'] == 2020]\n",
    "df_total = df_updated[df_updated['year'] != 2020]\n",
    "df_2020.reset_index(drop=True, inplace=True)\n",
    "df_total.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "06182201-9f4f-4b1b-80d2-b13b2af00aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 183180464.0000 - mae: 5454.5244 - mse: 183180464.0000\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5244 - mse: 183180464.0000\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 183180464.0000 - mae: 5454.5244 - mse: 183180464.0000\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5244 - mse: 183180464.0000\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5249 - mse: 183180464.0000\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5244 - mse: 183180480.0000\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180496.0000 - mae: 5454.5249 - mse: 183180496.0000\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183180496.0000 - mae: 5454.5244 - mse: 183180496.0000\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5244 - mse: 183180464.0000\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5254 - mse: 183180480.0000\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180496.0000 - mae: 5454.5249 - mse: 183180496.0000\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5249 - mse: 183180480.0000\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5249 - mse: 183180464.0000\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5249 - mse: 183180464.0000\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5249 - mse: 183180480.0000\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5254 - mse: 183180464.0000\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 183180480.0000 - mae: 5454.5249 - mse: 183180480.0000\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183180480.0000 - mae: 5454.5254 - mse: 183180480.0000\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5249 - mse: 183180480.0000\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5249 - mse: 183180464.0000\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5259 - mse: 183180464.0000\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180480.0000 - mae: 5454.5254 - mse: 183180480.0000\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183180464.0000 - mae: 5454.5254 - mse: 183180464.0000\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183180464.0000 - mae: 5454.5254 - mse: 183180464.0000\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183180480.0000 - mae: 5454.5259 - mse: 183180480.0000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 218362560.0000 - mae: 6693.9131 - mse: 218362560.0000\n",
      "Evaluation metrics:\n",
      "Loss: 218362560.0\n",
      "Mean Absolute Error (MAE): 6693.9130859375\n",
      "Mean Squared Error (MSE): 218362560.0\n"
     ]
    }
   ],
   "source": [
    "# Neural network time!\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_total['net_total'].astype(float)\n",
    "X = df_total.drop('net_total', axis=1).astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "net = Sequential()\n",
    "net.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "net.add(Dense(units=32, activation='relu'))\n",
    "net.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "net.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "net.fit(X_train, y_train, epochs=25, verbose=1, batch_size=50)\n",
    "\n",
    "# use it to predict testing data\n",
    "evaluation = net.evaluate(X_test, y_test)\n",
    "\n",
    "# Extract the evaluation metrics\n",
    "loss = evaluation[0]\n",
    "mae = evaluation[1]\n",
    "mse = evaluation[2]\n",
    "print(\"Evaluation metrics:\")\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0ece0850-c42c-419b-9142-ed4dfb0cd25d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "D wins by -3.8093944\n"
     ]
    }
   ],
   "source": [
    "# Then use it to predict data from 2020 election since it's closest to current election\n",
    "predictions_2020 = net.predict(df_2020.drop('net_total', axis=1))\n",
    "\n",
    "# Sum all the predictions\n",
    "total_prediction = predictions_2020.sum()\n",
    "\n",
    "# Check if the total prediction is positive, negative, or zero\n",
    "if total_prediction > 0:\n",
    "    print(\"R wins by \"+ str(total_prediction))\n",
    "elif total_prediction < 0:\n",
    "    print(\"D wins by \"+ str(total_prediction))\n",
    "else:\n",
    "    print(\"Cannot make a prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2c937042-aa1d-4c7d-8aca-f552269654ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 646245888.0000 - mae: 14268.1592 - mse: 646245888.0000\n",
      "Evaluation metrics on 2020 data:\n",
      "Loss: 646245888.0\n",
      "Mean Absolute Error (MAE): 14268.1591796875\n",
      "Mean Squared Error (MSE): 646245888.0\n"
     ]
    }
   ],
   "source": [
    "#Then evaluate the actual accuracy of the prediction. \n",
    "evaluation_2020 = net.evaluate(df_2020.drop('net_total', axis=1), df_2020['net_total'])\n",
    "\n",
    "# Extract the evaluation metrics\n",
    "loss_2020 = evaluation_2020[0]\n",
    "mae_2020 = evaluation_2020[1]\n",
    "mse_2020 = evaluation_2020[2]\n",
    "print(\"Evaluation metrics on 2020 data:\")\n",
    "print(f\"Loss: {loss_2020}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_2020}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_2020}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ede995bd-09d9-4efe-98cc-b7554b73a88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now for the linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "61319f9b-e36b-4150-b7c7-1ba7e41f7100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year           0\n",
      "county_fips    0\n",
      "net_total      0\n",
      "AV0AA          0\n",
      "B78AA          0\n",
      "              ..\n",
      "CL6AA          0\n",
      "AX7AA          0\n",
      "AX7AB          0\n",
      "BV8AA          0\n",
      "BV8AB          0\n",
      "Length: 163, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_lr = df_total.copy()\n",
    "print(df_lr.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "33ca97e8-0758-4b60-91dd-676807b9db52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  county_fips  net_total     AV0AA     B78AA    AV1AA    AV1AB  \\\n",
      "0  2000.0      51001.0     1260.0   38305.0   38305.0  18590.0  19715.0   \n",
      "1  2004.0      51001.0    -2208.0   38305.0   38305.0  18590.0  19715.0   \n",
      "2  2000.0      51003.0     2036.0   79236.0   79236.0  38002.0  41234.0   \n",
      "3  2004.0      51003.0      899.0   79236.0   79236.0  38002.0  41234.0   \n",
      "4  2000.0      51510.0   -14590.0  128283.0  128283.0  61974.0  66309.0   \n",
      "\n",
      "     AT5AA    AT5AB    AL8AA    AL8AB    AL8AC    AL8AD    AL8AE   AL8AF  \\\n",
      "0  36680.0   1625.0  22535.0  13983.0   4495.0    963.0   8010.0   515.0   \n",
      "1  36680.0   1625.0  22535.0  13983.0   4495.0    963.0   8010.0   515.0   \n",
      "2  73483.0   5753.0  39195.0  33535.0  12676.0   6028.0  11796.0  3035.0   \n",
      "3  73483.0   5753.0  39195.0  33535.0  12676.0   6028.0  11796.0  3035.0   \n",
      "4  95683.0  32600.0  27840.0  65288.0  21004.0  11976.0  26329.0  5979.0   \n",
      "\n",
      "    AL8AG  AL8AH    AL9AA    AL9AB    AL9AC    AL9AD    AL9AE   AL9AF   AL9AG  \\\n",
      "0   162.0    0.0  22535.0  13983.0   4495.0    963.0   8010.0   515.0   162.0   \n",
      "1   162.0    0.0  22535.0  13983.0   4495.0    963.0   8010.0   515.0   162.0   \n",
      "2   753.0    0.0  39195.0  33535.0  12676.0   6028.0  11796.0  3035.0   753.0   \n",
      "3   753.0    0.0  39195.0  33535.0  12676.0   6028.0  11796.0  3035.0   753.0   \n",
      "4  2555.0    0.0  27840.0  65288.0  21004.0  11976.0  26329.0  5979.0  2555.0   \n",
      "\n",
      "   AL9AH  AL9AI   AL9AJ   AK7AA   AK7AB   AK7AC  AK7AD    AK7AE  AK7AF  AB9AA  \\\n",
      "0    7.0    5.0   150.0   117.0   112.0     8.0    0.0   1388.0    0.0    0.0   \n",
      "1    7.0    5.0   150.0   117.0   112.0     8.0    0.0   1388.0    0.0    0.0   \n",
      "2   44.0   28.0   681.0  1732.0  2127.0   240.0  107.0   1547.0    0.0   25.0   \n",
      "3   44.0   28.0   681.0  1732.0  2127.0   240.0  107.0   1547.0    0.0   25.0   \n",
      "4  484.0   97.0  1974.0  2790.0  8059.0  7665.0   62.0  14024.0    0.0   68.0   \n",
      "\n",
      "   AB9AB  AB9AC  AB9AD  AB9AE  AB9AF  AB9AG  AB9AH  AB9AI  AB9AJ  AB9AK  \\\n",
      "0    0.0   32.0    3.0   10.0   27.0   11.0    0.0    2.0    2.0    0.0   \n",
      "1    0.0   32.0    3.0   10.0   27.0   11.0    0.0    2.0    2.0    0.0   \n",
      "2   19.0  489.0   25.0  111.0  330.0   77.0   50.0   88.0   18.0   43.0   \n",
      "3   19.0  489.0   25.0  111.0  330.0   77.0   50.0   88.0   18.0   43.0   \n",
      "4   38.0  558.0   18.0  239.0  517.0    9.0   96.0  114.0   17.0   24.0   \n",
      "\n",
      "   AB9AL  AB9AM  AB9AN  AB9AO  AB9AP  AB9AQ   AB9AR   AB9AS  AB9AT  AB9AU  \\\n",
      "0   12.0    4.0   14.0    0.0   19.0    4.0    89.0     8.0    0.0    0.0   \n",
      "1   12.0    4.0   14.0    0.0   19.0    4.0    89.0     8.0    0.0    0.0   \n",
      "2    8.0   79.0  216.0  154.0  779.0  155.0  1193.0   240.0  107.0    3.0   \n",
      "3    8.0   79.0  216.0  154.0  779.0  155.0  1193.0   240.0  107.0    3.0   \n",
      "4   87.0   97.0  568.0  340.0  561.0  203.0  7295.0  7665.0   62.0  143.0   \n",
      "\n",
      "    AB9AV  AB9AW    AB9AX  AB9AY  AJ6AA  AJ6AB  AJ6AC  AJ6AD  AJ6AE  AJ6AF  \\\n",
      "0   794.0   26.0    568.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1   794.0   26.0    568.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2   648.0  335.0    561.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3   648.0  335.0    561.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4  1119.0  467.0  12295.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   AJ6AG  AJ6AH  AJ6AI  AJ6AJ  AJ6AK  AJ6AL  AJ6AM  AJ6AN  AJ6AO  AJ6AP  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   AJ6AQ  AJ6AR  AJ6AS  AJ6AT  AJ6AU  AJ6AV  AJ6AW  AJ6AX  AJ6AY  AJ6AZ  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   AJ6BA  AJ6BB  AJ6BC  AJ6BD   B69AA    B69AB    B69AC    B84AA   B84AB  \\\n",
      "0    0.0    0.0    0.0    0.0  3078.0  19308.0   3508.0  18116.0   133.0   \n",
      "1    0.0    0.0    0.0    0.0  3078.0  19308.0   3508.0  18116.0   133.0   \n",
      "2    0.0    0.0    0.0    0.0  2844.0  25328.0  25675.0  41043.0   184.0   \n",
      "3    0.0    0.0    0.0    0.0  2844.0  25328.0  25675.0  41043.0   184.0   \n",
      "4    0.0    0.0    0.0    0.0  6282.0  37466.0  51982.0  80949.0  1861.0   \n",
      "\n",
      "     B84AC    B84AD   B84AE    B84AF   A63AA   A63AB    A63AC    A63AD  \\\n",
      "0  17983.0  16618.0  1365.0  11932.0   992.0  1744.0   3547.0   4795.0   \n",
      "1  17983.0  16618.0  1365.0  11932.0   992.0  1744.0   3547.0   4795.0   \n",
      "2  40859.0  39584.0  1275.0  20572.0  1517.0  3244.0   8830.0  11263.0   \n",
      "3  40859.0  39584.0  1275.0  20572.0  1517.0  3244.0   8830.0  11263.0   \n",
      "4  79088.0  76584.0  2504.0  27815.0  1625.0  7392.0  27998.0  19958.0   \n",
      "\n",
      "     A63AE   A63AF    BS4AA   BS4AB    BS4AC    BS4AD   BS4AE    BS4AF  \\\n",
      "0   6097.0   941.0   9542.0   130.0   9412.0   8743.0   669.0   4610.0   \n",
      "1   6097.0   941.0   9542.0   130.0   9412.0   8743.0   669.0   4610.0   \n",
      "2  14778.0  1411.0  21136.0   161.0  20975.0  20357.0   618.0   8039.0   \n",
      "3  14778.0  1411.0  21136.0   161.0  20975.0  20357.0   618.0   8039.0   \n",
      "4  22133.0  1843.0  41538.0  1409.0  40129.0  38929.0  1200.0  10566.0   \n",
      "\n",
      "     BS4AG  BS4AH    BS4AI    BS4AJ   BS4AK    BS4AL  A67AA   A67AB    A67AC  \\\n",
      "0   8574.0    3.0   8571.0   7875.0   696.0   7322.0  479.0   871.0   1883.0   \n",
      "1   8574.0    3.0   8571.0   7875.0   696.0   7322.0  479.0   871.0   1883.0   \n",
      "2  19907.0   23.0  19884.0  19227.0   657.0  12533.0  736.0  1629.0   4505.0   \n",
      "3  19907.0   23.0  19884.0  19227.0   657.0  12533.0  736.0  1629.0   4505.0   \n",
      "4  39411.0  452.0  38959.0  37655.0  1304.0  17249.0  726.0  3748.0  14338.0   \n",
      "\n",
      "     A67AD    A67AE  A67AF  A67AG   A67AH    A67AI   A67AJ    A67AK  A67AL  \\\n",
      "0   2545.0   3201.0  563.0  513.0   873.0   1664.0  2250.0   2896.0  378.0   \n",
      "1   2545.0   3201.0  563.0  513.0   873.0   1664.0  2250.0   2896.0  378.0   \n",
      "2   5693.0   7711.0  862.0  781.0  1615.0   4325.0  5570.0   7067.0  549.0   \n",
      "3   5693.0   7711.0  862.0  781.0  1615.0   4325.0  5570.0   7067.0  549.0   \n",
      "4  10610.0  11123.0  993.0  899.0  3644.0  13660.0  9348.0  11010.0  850.0   \n",
      "\n",
      "     C54AA    C54AB   C54AC   C54AD  C54AE  C54AF   C54AG  C54AH   C54AI  \\\n",
      "0  14839.0    256.0   256.0     0.0    0.0    0.0   422.0  333.0   454.0   \n",
      "1  14839.0    256.0   256.0     0.0    0.0    0.0   422.0  333.0   454.0   \n",
      "2  35542.0    640.0   616.0    18.0    6.0   24.0   594.0  326.0  2011.0   \n",
      "3  35542.0    640.0   616.0    18.0    6.0   24.0   594.0  326.0  2011.0   \n",
      "4  58645.0  12279.0  4994.0  7192.0   93.0  358.0  2289.0  927.0  2692.0   \n",
      "\n",
      "   C50AA   C50AB   C50AC   C50AD    C50AE    C50AF    C50AG   C50AH  \\\n",
      "0  919.0  2429.0  2813.0  2681.0   3206.0   1979.0    725.0  1098.0   \n",
      "1  919.0  2429.0  2813.0  2681.0   3206.0   1979.0    725.0  1098.0   \n",
      "2  764.0  3099.0  6453.0  8199.0   9931.0   6076.0   1097.0  1507.0   \n",
      "3  764.0  3099.0  6453.0  8199.0   9931.0   6076.0   1097.0  1507.0   \n",
      "4  959.0  3541.0  7414.0  9888.0  15737.0  20663.0  10375.0  5921.0   \n",
      "\n",
      "       C98AA   BS7AA   BS7AB   BS7AC    BS7AD    B79AA   A88AA  A88AB   A88AC  \\\n",
      "0   364875.0  2186.0  1339.0  2799.0   8946.0  30250.0   846.0  757.0  1803.0   \n",
      "1   364875.0  2186.0  1339.0  2799.0   8946.0  30250.0   846.0  757.0  1803.0   \n",
      "2   828400.0  1976.0  1383.0  3162.0  25395.0  50749.0   577.0  506.0  1523.0   \n",
      "3   828400.0  1976.0  1383.0  3162.0  25395.0  50749.0   577.0  506.0  1523.0   \n",
      "4  2210800.0  3408.0  1949.0  4754.0  51857.0  56054.0  1213.0  866.0  2114.0   \n",
      "\n",
      "    A88AD    A88AE    AB2AA    BD5AA     AX6AA    CL6AA    AX7AA     AX7AB  \\\n",
      "0  3781.0   3195.0  34821.0  16309.0   37715.0   6788.0   6788.0   30927.0   \n",
      "1  3781.0   3195.0  34821.0  16309.0   37715.0   6788.0   6788.0   30927.0   \n",
      "2  5153.0  13401.0  63407.0  28852.0   77661.0   5232.0   5232.0   72429.0   \n",
      "3  5153.0  13401.0  63407.0  28852.0   77661.0   5232.0   5232.0   72429.0   \n",
      "4  6275.0  17685.0  67023.0  37645.0  126409.0  11279.0  11279.0  115130.0   \n",
      "\n",
      "   BV8AA   BV8AB  \n",
      "0  957.0  5291.0  \n",
      "1  957.0  5291.0  \n",
      "2  430.0  8756.0  \n",
      "3  430.0  8756.0  \n",
      "4  939.0  9547.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(df_lr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f282c7d3-afb9-48d8-8c6e-f691d31a21d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lr.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6a8a32ab-ed27-4669-b5a7-887fbc3a0d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
      "/tmp/ipykernel_162990/789614483.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n"
     ]
    }
   ],
   "source": [
    "for column in df_lr.columns:\n",
    "    df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b5878c4d-a45e-4a59-b9aa-8ff51655e4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (670, 326), indices imply (670, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_lg \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_total\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming df_total is prepared with necessary preprocessing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df_lg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_total\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    711\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    712\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    713\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (670, 326), indices imply (670, 12)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "df_lg = pd.DataFrame(imputer.fit_transform(df_total), columns = df.columns)\n",
    "\n",
    "# Assuming df_total is prepared with necessary preprocessing\n",
    "y = df_lg['net_total'].astype(float)\n",
    "X = df_lg.drop('net_total', axis=1).astype(float)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbffca-406b-4e11-a5cb-dcc56432c283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "57bf8620-e398-440a-a152-c259dd56f28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year           0\n",
      "county_fips    0\n",
      "AV0AA          1\n",
      "B78AA          1\n",
      "AV1AA          1\n",
      "              ..\n",
      "CL6AA          1\n",
      "AX7AA          1\n",
      "AX7AB          1\n",
      "BV8AA          1\n",
      "BV8AB          1\n",
      "Length: 162, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X.isna().sum())\n",
    "print(y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "625c47e0-359b-4311-aabf-4b330a509cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b5c6e95d-7781-482e-bd5a-603213c61d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the lr model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b48ce1db-083c-45d8-8c98-45e7a3d84576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[203], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fitting\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py:649\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    645\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    647\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 649\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    654\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    655\u001b[0m )\n\u001b[1;32m    657\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    658\u001b[0m     X,\n\u001b[1;32m    659\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    663\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# fitting\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f60c0b1-b098-4843-91db-02d383203005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# evaluating model accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, \u001b[43my_pred\u001b[49m)\n\u001b[1;32m      3\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluating model accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0dc3c5d-a93e-4fc6-b7a5-4b03c865bccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ba13e-5db6-4a92-8029-e040303422c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = df.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63c44a-d39e-44c5-80c9-c8f876c3c191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scatter plot with a regression line\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x='feature_1', y='target_variable', data=df, scatter_kws={\"s\": 50}, line_kws={\"color\": \"red\"})\n",
    "plt.title('Feature vs Target with Regression Line')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e9111-aa77-42db-bf68-85ee1cec6642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
