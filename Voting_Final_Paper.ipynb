{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d08bab-6e61-4c50-b134-8b29c948289e",
   "metadata": {},
   "source": [
    "Flavien Moise, Tenzin Nargee, Charlie Payne, Duncan Tanner\n",
    "\n",
    "5.7.2024\n",
    "\n",
    "Professor Johnson\n",
    "\n",
    "DS 3001\n",
    "\n",
    "# Voting Project Findings\n",
    "\n",
    "## Summary\n",
    "The goal of our project was to build predictive models for the 2024 presidential election results in the state of Virginia. To do so, we used voting data from 2000 to 2020 on presidential elections in Virginia, as well as county-level data. We first used an exploratory data analysis to gain a clear understanding of what the data looks like. Our predictive models included a neural network and linear regression, which were used to predict a winner of the 2024 Virginia election, either Democrat (D) or Republican (R). We faced a handful of challenges in the data-cleaning process, significantly limiting our freedom of prediction and overall results. The data, overall, was noisy, a problem for us when addressing data scaling and normalization, which led to worse results and weaker predictions.\n",
    "\n",
    "## Data\n",
    "We began our process by cleaning data from “voting_VA.” We dropped unnecessary columns, such as “Unnamed: 0” using “df.drop()”. We then examined the consistency of the data, using .unique(), to ensure the data only included variables that were looking for, including state, state_po, office, and mode. We wanted to ensure the data only included information on Virginia votes for President and checked to see if any action was needed. \n",
    "We decided to examine correlations between voting including the mode as an independent variable, so we used “.astype(‘category’)” to provide a data frame where the modes aggregate all individual records across different voting modes into a single record per candidate per county per election year. We put this data into a new data frame called “df_aggregated.”\n",
    "The next step in cleaning was to drop unimportant information from the aggregated data frame, such as candidate and third-party information. We then reorganized the data into “df_real,” after merging and dropping some more columns, we created “df_final.” After creating “df_final,” we converted column data into the same data type: “str,” and then merged it with “df_melt,” which was provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3bcc39-23d2-427a-95c9-14e8b1d1408c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  year     state state_po county_name  county_fips        office  \\\n",
      "0       11161  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "1       11162  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "2       11163  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "3       11164  2000  VIRGINIA       VA    ACCOMACK        51001  US PRESIDENT   \n",
      "4       11165  2000  VIRGINIA       VA   ALBEMARLE        51003  US PRESIDENT   \n",
      "\n",
      "        candidate       party  candidatevotes  totalvotes   version   mode  \n",
      "0         AL GORE    DEMOCRAT            5092       11925  20220315  TOTAL  \n",
      "1  GEORGE W. BUSH  REPUBLICAN            6352       11925  20220315  TOTAL  \n",
      "2     RALPH NADER       GREEN             220       11925  20220315  TOTAL  \n",
      "3           OTHER       OTHER             261       11925  20220315  TOTAL  \n",
      "4         AL GORE    DEMOCRAT           16255       36846  20220315  TOTAL  \n",
      "Unnamed: 0        0\n",
      "year              0\n",
      "state             0\n",
      "state_po          0\n",
      "county_name       0\n",
      "county_fips       0\n",
      "office            0\n",
      "candidate         0\n",
      "party             0\n",
      "candidatevotes    0\n",
      "totalvotes        0\n",
      "version           0\n",
      "mode              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/voting_VA.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3e152a-e588-4915-bbe8-136611121286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VIRGINIA']\n",
      "['VA']\n",
      "['US PRESIDENT']\n",
      "['TOTAL' 'ABSENTEE' 'ELECTION DAY' 'PROVISIONAL']\n"
     ]
    }
   ],
   "source": [
    "# Remove the 'Unnamed: 0' column\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Check unique values for certain columns to ensure consistency\n",
    "print(df['state'].unique())  # Should only contain \"VIRGINIA\"\n",
    "print(df['state_po'].unique())  # Should only contain \"VA\"\n",
    "print(df['office'].unique())  # Should only contain \"US PRESIDENT\"\n",
    "print(df['mode'].unique())  # Check if any action is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46c0402-da7f-41d9-b5c5-670390aa54dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TOTAL\n",
       "1    TOTAL\n",
       "2    TOTAL\n",
       "3    TOTAL\n",
       "4    TOTAL\n",
       "Name: mode, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18e9068-850b-4f74-b55a-32ce52498787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TOTAL\n",
       "1    TOTAL\n",
       "2    TOTAL\n",
       "3    TOTAL\n",
       "4    TOTAL\n",
       "Name: mode, dtype: category\n",
       "Categories (4, object): ['ABSENTEE', 'ELECTION DAY', 'PROVISIONAL', 'TOTAL']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we're interested in overall voting results without differentiating between the modes:\n",
    "# df_total = df[df['mode'] == 'TOTAL']\n",
    "# df_total.to_csv(\"data/clean_total_voting_VA.csv\", index=False) \n",
    "\n",
    "# Otherwise, we can keep all of the modes of voting and use them as features\n",
    "# in our models\n",
    "df['mode'] = df['mode'].astype('category')\n",
    "df['mode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65e6420-3eae-44f6-8c64-42f885fb0b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>candidatevotes</th>\n",
       "      <th>totalvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5092</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>GEORGE W. BUSH</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>6352</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>261</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>RALPH NADER</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>220</td>\n",
       "      <td>11925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALBEMARLE</td>\n",
       "      <td>51003</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>16255</td>\n",
       "      <td>36846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year county_name  county_fips       candidate       party  candidatevotes  \\\n",
       "0  2000    ACCOMACK        51001         AL GORE    DEMOCRAT            5092   \n",
       "1  2000    ACCOMACK        51001  GEORGE W. BUSH  REPUBLICAN            6352   \n",
       "2  2000    ACCOMACK        51001           OTHER       OTHER             261   \n",
       "3  2000    ACCOMACK        51001     RALPH NADER       GREEN             220   \n",
       "4  2000   ALBEMARLE        51003         AL GORE    DEMOCRAT           16255   \n",
       "\n",
       "   totalvotes  \n",
       "0       11925  \n",
       "1       11925  \n",
       "2       11925  \n",
       "3       11925  \n",
       "4       36846  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provides a dataframe where the modes aggregates all individual records across different voting modes \n",
    "# into a single record per candidate per county per election year. \n",
    "\n",
    "df_aggregated = df.groupby(['year', 'county_name', 'county_fips', 'candidate', 'party']).agg({\n",
    "    'candidatevotes': 'sum',\n",
    "    'totalvotes': 'max'  # Assuming totalvotes is the same across all modes, otherwise sum might be needed\n",
    "}).reset_index()\n",
    "\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36270091-d53c-4c0a-8419-0051ad8d6cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>net_total</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>1260</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALBEMARLE</td>\n",
       "      <td>51003</td>\n",
       "      <td>2036</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALEXANDRIA</td>\n",
       "      <td>51510</td>\n",
       "      <td>-14590</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ALLEGHANY</td>\n",
       "      <td>51005</td>\n",
       "      <td>594</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>AMELIA</td>\n",
       "      <td>51007</td>\n",
       "      <td>1193</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year county_name  county_fips  net_total      winner\n",
       "0  2000    ACCOMACK        51001       1260  REPUBLICAN\n",
       "1  2000   ALBEMARLE        51003       2036  REPUBLICAN\n",
       "2  2000  ALEXANDRIA        51510     -14590    DEMOCRAT\n",
       "3  2000   ALLEGHANY        51005        594  REPUBLICAN\n",
       "4  2000      AMELIA        51007       1193  REPUBLICAN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing candidates column (unimportant)\n",
    "df_real = df_aggregated.drop('candidate', axis=1)\n",
    "\n",
    "# Removing third parties (also unimportant)\n",
    "df_real = df_real[~df_real['party'].isin(['OTHER', 'GREEN'])]\n",
    "\n",
    "# Finding net total votes\n",
    "df_real['net_total'] = df_real.groupby(['year', 'county_name', 'county_fips', 'totalvotes'])['candidatevotes'].transform(lambda x: x.iloc[1] - x.iloc[0])\n",
    "\n",
    "# Merging columns\n",
    "df_real = df_real.groupby(['year', 'county_name', 'county_fips', 'totalvotes', 'net_total']).agg({'party': ', '.join}).reset_index()\n",
    "df_real['winner'] = df_real['net_total'].apply(lambda x: 'REPUBLICAN' if x > 0 else 'DEMOCRAT')\n",
    "# Dropping some more columns\n",
    "df_real = df_real.drop(['party', 'totalvotes'], axis=1)\n",
    "df_final = df_real[['year', 'county_name', 'county_fips','net_total', 'winner']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f76eb42-c3f3-48d0-90ed-ff0c29db6f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year county_name county_fips  net_total      winner     AV0AA     B78AA  \\\n",
      "0  2000    ACCOMACK       51001       1260  REPUBLICAN   38305.0   38305.0   \n",
      "1  2004    ACCOMACK       51001      -2208    DEMOCRAT   38305.0   38305.0   \n",
      "2  2000   ALBEMARLE       51003       2036  REPUBLICAN   79236.0   79236.0   \n",
      "3  2004   ALBEMARLE       51003        899  REPUBLICAN   79236.0   79236.0   \n",
      "4  2000  ALEXANDRIA       51510     -14590    DEMOCRAT  128283.0  128283.0   \n",
      "\n",
      "     AV1AA    AV1AB    AT5AA  ...   A88AD    A88AE    AB2AA    BD5AA  \\\n",
      "0  18590.0  19715.0  36680.0  ...  3781.0   3195.0  34821.0  16309.0   \n",
      "1  18590.0  19715.0  36680.0  ...  3781.0   3195.0  34821.0  16309.0   \n",
      "2  38002.0  41234.0  73483.0  ...  5153.0  13401.0  63407.0  28852.0   \n",
      "3  38002.0  41234.0  73483.0  ...  5153.0  13401.0  63407.0  28852.0   \n",
      "4  61974.0  66309.0  95683.0  ...  6275.0  17685.0  67023.0  37645.0   \n",
      "\n",
      "      AX6AA    CL6AA    AX7AA     AX7AB  BV8AA   BV8AB  \n",
      "0   37715.0   6788.0   6788.0   30927.0  957.0  5291.0  \n",
      "1   37715.0   6788.0   6788.0   30927.0  957.0  5291.0  \n",
      "2   77661.0   5232.0   5232.0   72429.0  430.0  8756.0  \n",
      "3   77661.0   5232.0   5232.0   72429.0  430.0  8756.0  \n",
      "4  126409.0  11279.0  11279.0  115130.0  939.0  9547.0  \n",
      "\n",
      "[5 rows x 165 columns]\n"
     ]
    }
   ],
   "source": [
    "df_melt = pd.read_csv(\"data/df_melt.csv\")\n",
    "\n",
    "year_mapping = {\n",
    "    2000: 2000,\n",
    "    2004: 2000,\n",
    "    2008: 125,\n",
    "    2012: 125,\n",
    "    2016: 195,\n",
    "    2020: 195\n",
    "}\n",
    "df_final['melt_year'] = df_final['year'].map(year_mapping)\n",
    "\n",
    "# Convert columns to the same data type before merging\n",
    "df_final['melt_year'] = df_final['melt_year'].astype(str)\n",
    "df_final['county_fips'] = df_final['county_fips'].astype(str)\n",
    "df_melt['YEAR'] = df_melt['YEAR'].astype(str)\n",
    "df_melt['FIPS'] = df_melt['FIPS'].astype(str)\n",
    "\n",
    "merged_df = pd.merge(df_final, df_melt, left_on=['melt_year', 'county_fips'], right_on=['YEAR', 'FIPS'])\n",
    "\n",
    "columns_to_drop = ['YEAR', 'FIPS', 'melt_year']\n",
    "df_updated = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(df_updated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d537c9aa-778d-4f1a-b57a-083235e8e41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_updated = df_updated.drop(columns=['winner'])\n",
    "df_updated = pd.get_dummies(df_updated, columns=['county_name'])\n",
    "df_updated = df_updated.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb621d-3a0b-4986-93a6-72410eed021a",
   "metadata": {},
   "source": [
    "#### Challenges:\n",
    "Our biggest challenge in the cleaning process was merging county voting data with county data based on year and fids. We ran into significant bugs and index errors with the concatenation of these two data and ultimately used “df_melt” to get around these problems before running our regression.\n",
    "Bugs were a huge limitation in our process.\n",
    "\n",
    "## Results\n",
    "\n",
    "#### EDA\n",
    "The initial steps for the Exploratory Data Analysis involved loading the data, normalizing numeric variables using a MinMaxScaler, and transforming certain skewed variables using the arcsinh transformation. The transformation of “net_total” into “net_total_ihs” using the arcsinh function is meant to stabilize variance and normalize the distribution of heavily skewed variables.\n",
    "The resulting graphs were quite messy. Looking at the scatter plots, we can see that many plots show a strong linear relationship, a good sign for linear predictive modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81531091-9c8e-4a31-b6b6-b4a0d0541e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                           0\n",
      "county_fips                    0\n",
      "net_total                      0\n",
      "AV0AA                          1\n",
      "B78AA                          1\n",
      "                              ..\n",
      "county_name_WINCHESTER         0\n",
      "county_name_WINCHESTER CITY    0\n",
      "county_name_WISE               0\n",
      "county_name_WYTHE              0\n",
      "county_name_YORK               0\n",
      "Length: 330, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222010/3079268672.py:13: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n",
      "  plt.tight_layout()  # Adjust subplots to fit into figure area.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_eda = df_updated.copy(deep=True)\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print(df_eda.isnull().sum())\n",
    "\n",
    "# Histograms for numeric data to understand distributions\n",
    "df_eda.hist(figsize=(12, 10), bins=20)\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()\n",
    "\n",
    "''' # Boxplots for numerical columns to visualize outliers\n",
    "numeric_cols = df_eda.select_dtypes(include=[np.number]).columns.tolist()\n",
    "fig, ax = plt.subplots(len(numeric_cols), 1, figsize=(10, len(numeric_cols)*4))\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.boxplot(x=col, data=df, ax=ax[i])\n",
    "    ax[i].set_title(f'Boxplot for {col}', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# Correlation matrix to explore potential relationships\n",
    "corr_matrix = df_eda.corr()\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for selected features including the transformed net_total\n",
    "selected_features = [col for col in df_eda.columns if 'AV' in col][:5]  # example with AV columns\n",
    "sns.pairplot(df_eda[selected_features])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e7597-828b-42cc-8096-2404883cab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize net_total using inverse hyperbolic arcsin\n",
    "df_updated['net_total'] = np.arcsinh(df_updated['net_total'])\n",
    "#normalize the rest of the variables (they're all counts) except for 'year', 'net_total' and 'county_fips'\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = df_updated.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_cols = ['year', 'county_fips', 'net_total']\n",
    "numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "df_updated[numeric_cols] = scaler.fit_transform(df_updated[numeric_cols])\n",
    "\n",
    "print(df_updated.head())\n",
    "\n",
    "df_2020 = df_updated[df_updated['year'] == 2020]\n",
    "df_total = df_updated[df_updated['year'] != 2020]\n",
    "df_2020.reset_index(drop=True, inplace=True)\n",
    "df_total.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4548a0-8151-4ab4-9382-ad64a47cd61c",
   "metadata": {},
   "source": [
    "#### Neural Network\n",
    "We started our analysis with a neural network after getting past challenges with cleaning the data. The neural network model was employed to predict net total votes defined in the data frame “df_total.” Data was split into training and testing samples at an 80:20 ratio. The model consisted of three layers configured with 64, 32, and 1 units, respectively. We used a Rectified Linear Unit activation function for the first three layers, and a linear activation function for the output layer. We used the Adam optimizer and mean squared error as the loss function, and mean absolute error (MAE) and mean squared error (MSE) as performance tracking metrics. \n",
    "\n",
    "We evaluated the model using the training data. Initial testing showed a loss/MSE of 218362576.0 and an MAE of 6693.91. The results showed high error, suggesting potential issues including overfitting or inadequately captured interactions between features.\n",
    "After using training data, we applied the model to predict results based on the 2020 election, since data from that year is closest to the next election, and thus more helpful. We summed all predictions from 2020 data to create one prediction for the 2024 election. Our resulting prediction was that Republicans  would win by a margin of 3.4022. \n",
    "\n",
    "We checked the accuracy of this precision using previously mentioned metrics. Using 2020 data, loss/MSE was 94.948, and MAE was 9.686. The loss and MSE were relatively high, suggesting that the model’s predictions vary significantly from actual values. These results indicate significant prediction errors on average and that the neural network model does not perform optimally for this intended task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f84dfb-e060-4fb0-a7ed-734e869f31b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neural network time!\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = df_total['net_total'].astype(float)\n",
    "X = df_total.drop('net_total', axis=1).astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "net = Sequential()\n",
    "#Having 3 layers results in Loss: 218362592.0, Mean Absolute Error (MAE): 6693.912109375, Mean Squared Error (MSE): 218362592.0\n",
    "net.add(Dense(units=82, activation='relu', input_dim=X_train.shape[1]))\n",
    "#net.add(Dense(units=32, activation='relu'))\n",
    "net.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "net.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "net.fit(X_train, y_train, epochs=25, verbose=1, batch_size=50)\n",
    "\n",
    "# use it to predict testing data\n",
    "evaluation = net.evaluate(X_test, y_test)\n",
    "\n",
    "# Extract the evaluation metrics\n",
    "loss = evaluation[0]\n",
    "mae = evaluation[1]\n",
    "mse = evaluation[2]\n",
    "print(\"Evaluation metrics:\")\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9053e-079e-4227-bf61-ce7c1338fd76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then use it to predict data from 2020 election since it's closest to current election\n",
    "test_2020 = df_2020.drop('net_total', axis=1)\n",
    "print(test_2020.head())\n",
    "predictions_2020 = net.predict(test_2020)\n",
    "\n",
    "# Sum all the predictions\n",
    "total_prediction = predictions_2020.sum()\n",
    "\n",
    "# Check if the total prediction is positive, negative, or zero\n",
    "if total_prediction > 0:\n",
    "    print(\"R wins by \"+ str(total_prediction))\n",
    "elif total_prediction < 0:\n",
    "    print(\"D wins by \"+ str(total_prediction))\n",
    "else:\n",
    "    print(\"Cannot make a prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6b09a-e097-48f4-871c-67d2b801cc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Then evaluate the actual accuracy of the prediction. \n",
    "evaluation_2020 = net.evaluate(df_2020.drop('net_total', axis=1), df_2020['net_total'])\n",
    "\n",
    "# Extract the evaluation metrics\n",
    "loss_2020 = evaluation_2020[0]\n",
    "mae_2020 = evaluation_2020[1]\n",
    "mse_2020 = evaluation_2020[2]\n",
    "print(\"Evaluation metrics on 2020 data:\")\n",
    "print(f\"Loss: {loss_2020}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_2020}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_2020}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbec24-1904-4167-955b-01415ead4b6e",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "There were 163 NaN values in the data frame, which had to be removed to run a linear regression.  We ran into substantial difficulty replacing these NaN values. We first tried mean/median imputation, but indexing errors prevented the imputation (Ex. “Shape of passed values is (670, 326), indices imply (670, 12)”), Next we tried replacing NaN values with zeros and creating respective binary columns using 1 as an indicator of a missing value. This resulted in significant warnings, such as “PerformanceWarning: DataFrame is highly fragmented,”  due to repeated modifications to the data frame when we replaced NaNs with ‘0’ using “fillna().”\n",
    "\n",
    "When running the linear regression model, we again split the data into testing and training data, at an 80:20 ratio. We applied the prediction model first to the entire data set, which predicted a Republican win in 2024 by a margin of 56.79. When we just used 2020 data to make a prediction however, we observed a Democrat win by a margin of -1832. The accuracy metrics of the prediction resulted in an MSE of 3108.369 and an r2 of -45.747. The MSE is exceptionally high. This suggests that the model’s predictions deviate significantly from the actual values in the data set, and indicates extremely poor model performance. The r2 of -45.747 is extraordinarily poor. An r2 of 0 would indicate that the model performs no better than a model that predicts the mean of the target variable, disregarding input features. The r2 here indicates that the model performs worse than the baseline model. \n",
    "Reasons for such poor performance could be significant underfitting of the data or high variance in the data that the simple linear regression model is poor at comprehending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3c9e5-cd24-49e9-953a-2050a33fdf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lr = df_updated.copy()\n",
    "print(df_lr.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb2afa-1dc4-4388-9ef5-375496913db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(df_lr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1b88d-283d-4cb2-8277-238cd13f3d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in df_lr.columns:\n",
    "    df_lr[f'missing_indicator_{column}'] = df_lr[column].isna().astype(int)\n",
    "df_lr.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa15c5-2d42-4c64-a7f5-4c4b077ae73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "transformed_data = imputer.fit_transform(df_lr)\n",
    "df_lr = pd.DataFrame(transformed_data, columns=df_lr.columns)\n",
    "\n",
    "print(df_lr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9a57b-3d8a-48a5-b40c-208941cc5b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming df_updated is prepared with necessary preprocessing\n",
    "df_lr2020 = df_lr[df_updated['year'] == 2020]\n",
    "df_lrrest = df_lr[df_updated['year'] != 2020]\n",
    "df_lr2020.reset_index(drop=True, inplace=True)\n",
    "df_lrrest.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y = df_lrrest['net_total'].astype(float)\n",
    "X = df_lrrest.drop('net_total', axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf17a6-e827-44b2-a4af-24b113940607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X.isna().sum())\n",
    "print(y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6491e-3d1a-4e90-8dd9-bf17e0d6bb34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# The LR model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fitting\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976d8a7-41e6-435a-a6d4-137f530d5213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Prediction: \" , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490c078-e2af-4bb7-92df-df9953db6307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)  # Line for perfect predictions\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f832442-2c64-4c52-8c96-ab4c23a70909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating model accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662afff7-c96b-4111-8366-d723d07cfe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5354af-fca7-48fa-a691-fd31441d5deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = df_lr.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc67869-4259-4b6f-886b-d3678ad168c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predicting 2024 election with 2020 data, since we dont have 2024 data\n",
    "lrtest_2020 = df_lr2020.drop('net_total', axis=1)\n",
    "y_pred2020 = model.predict(lrtest_2020)\n",
    "total_prediction = y_pred2020.sum()\n",
    "# Check if the total prediction is positive, negative, or zero\n",
    "if total_prediction > 0:\n",
    "    print(\"R wins by \"+ str(total_prediction))\n",
    "elif total_prediction < 0:\n",
    "    print(\"D wins by \"+ str(total_prediction))\n",
    "else:\n",
    "    print(\"Cannot make a prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ba29d-91de-41df-b5b0-9c3fda48dd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "rf = model.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R^2) Score:\", r2)\n",
    "sns.scatterplot(x=y_test, y=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84035e-36c3-4363-9b50-e63244743eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred2020 = rf.predict(df_lr2020.drop('net_total', axis=1))\n",
    "total_prediction = pred2020.sum()\n",
    "if total_prediction > 0:\n",
    "    print(\"R wins by \"+ str(total_prediction))\n",
    "elif total_prediction < 0:\n",
    "    print(\"D wins by \"+ str(total_prediction))\n",
    "else:\n",
    "    print(\"Cannot make a prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d7a63-0d0c-4014-b807-17f927d65b63",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our project aimed to develop a predictive framework for the 2024 presidential election results in Virginia using historical voting data paired with county-level data. The process involved data preparation, exploratory data analysis (EDA), and implementing two predictive models: neural network and linear regression. \n",
    "\n",
    "We encountered multiple challenges, namely, concatenating the VA county voting data with other county data based on year and FIPS. Ultimately, we turned to the melted CSV to get past these problems. Other limitations of our predictive models included a lack of quality training data and 2024 data, so the best we could do is predict using 2020 data since it is the most recent data. Ultimately, bugs we faced during data cleaning significantly impacted our ability to use a variety of more complex predictive models. \n",
    "\n",
    "The EDA was instrumental in uncovering the structure of the data and highlighted some relationships and distributions that were informative in the later predictive models. By normalizing numerical variables and addressing missing values and outliers, we created an aggregated data set to use as a foundation.\n",
    "\n",
    "Our neural network model, despite tuning, encountered challenges with high loss and MAE, indicating potential overfitting and a failure to capture feature interaction adequately. The model predicted a Democrat win in 2024 by a margin of -3.526. However, the prediction was ultimately weak and faced significant accuracy errors.\n",
    "The linear regression model showed an extremely high r2 of -45.747 and predicted a Democrat win in 2024 by over 1000 difference. The results from linear regression can be attributed to our challenges in handling missing data and the lack of data scaling and normalization. It also suggests that a linear regression model might be too simple for this inherently complex prediction challenge. \n",
    "\n",
    "In reflection, it is clear that the accuracy and reliability of our models need enhancement. Future work could incorporate additional data, such as broader demographic, economic, and more granular voting data, which would address issues with the strength of our training data. We could also incorporate more advanced modeling techniques absent our issues in merging county data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
